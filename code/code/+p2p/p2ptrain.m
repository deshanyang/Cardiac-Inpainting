function p2pModel = p2ptrain(inData, outData, options)
% train     Train a pix2pix model.
%
%   A pix2pix model that attempts to learn how to convert images from
%   inData to outData is trained, following the approach described in
%   'Isola et al. Image-to-Image Translation with Conditional Adversarial
%   Nets'.
%
% Args:
%   inData  - Training data input images
%   outData - Training data target images
%   options - Training options as a struct generated by p2p.trainingOptions
%
% Returns:
%   p2pModel - A struct containing trained newtorks and optimisiers
%
% See also: p2p.trainingOptions

% Copyright 2020 The MathWorks, Inc.

if nargin < 3
	options = p2p.getDefaultOptions();
end

if (options.ExecutionEnvironment == "auto" && canUseGPU) || ...
		options.ExecutionEnvironment == "gpu"
	env = @gpuArray;
else
	env = @(x) x;
end

if ~isempty(options.CheckpointPath)
	% Make a subfolder for storing checkpoints
	timestamp = strcat("p2p-", datestr(now, 'yyyymmdd-HHMMSS'));
	checkpointSubDir = fullfile(options.CheckpointPath, timestamp);
	mkdir(checkpointSubDir)
end

combinedChannels = options.InputChannels + options.OutputChannels;

% model learns A to B mapping
%     if options.InputChannels>3
%         imageAndLabel = p2p.data.PairedImageDatastore3D(inData, outData, options.MiniBatchSize, ...
%             "PreSize", options.PreSize, "CropSize", options.InputSize, "RandXReflection", options.RandXReflection, ...
%             "ARange", options.ARange, "BRange", options.BRange);
%     else
%
imageAndLabel = p2p.data.PairedImageDatastore(inData, outData, options.MiniBatchSize, ...
	"PreSize", options.PreSize, "CropSize", options.InputSize, "RandXReflection", options.RandXReflection, ...
	"ARange", options.ARange, "BRange", options.BRange);
%     end

if options.Plots == "training-progress"
	examples = imageAndLabel.shuffle();
	nExamples = 90;
	examples.MiniBatchSize = nExamples;
	data = examples.read();
	%         thisInput = min(max(thisInput, -0.2),0.2);
	if options.InputChannels>3
		thisInput = cat(5, data.A{:});
		exampleInputs = dlarray(env(thisInput), 'SSSCB');
	else
		thisInput = cat(4, data.A{:});
		exampleInputs = dlarray(env(thisInput), 'SSCB');
	end
	trainingPlot = p2p.vis.TrainingPlot(exampleInputs);
end

if isempty(options.ResumeFrom)
	if options.InputChannels>3
		% 3D
		g0 = createUnet3dLayers_Trevor([options.InputSize options.InputChannels], 1, 'EncoderDepth', options.GDepth, 'BatchNormalizationFirstLayer', false, 'InputNormalization', false, ...
			'NumEncoderFilters', [16 32 48 64 96 128], 'NumDecoderFilters', [128 96 64 48 32 16], 'Z_Half_SampleRates', [1 1 2 2 1 1], 'DownSamplePooling', 'max');
		%             g0 = createUnet3dLayers_Deshan([options.InputSize options.InputChannels], 1, 'EncoderDepth', options.GDepth, 'BatchNormalizationFirstLayer', false, 'InputNormalization', false, ...
		%                 'NumEncoderFilters', [16 32 48 64 96 128], 'NumDecoderFilters', [128 96 64 64 64 32], 'Z_Half_SampleRates', [2 2 1 1 1], 'DownSamplePooling', 'average');
		g0 = removeLayers(g0, {'Segmentation-Layer', 'Softmax-Layer'});
		g = dlnetwork(g0);
		d = p2p.networks.discriminator3d([options.InputSize options.InputChannels], 2, options.DDepth);
	else
		g = p2p.networks.generator(options.InputSize, options.InputChannels, options.OutputChannels, options.GDepth);
		d = p2p.networks.discriminator(options.InputSize, combinedChannels, options.DDepth);
	end
	
	gOptimiser = p2p.util.AdamOptimiser(options.GLearnRate, options.GBeta1, options.GBeta2);
	dOptimiser = p2p.util.AdamOptimiser(options.DLearnRate, options.DBeta1, options.DBeta2);
	
	iteration = 0;
	startEpoch = 1;
else
	data = load(options.ResumeFrom, 'p2pModel');
	g = data.p2pModel.g;
	d = data.p2pModel.d;
	gOptimiser = data.p2pModel.gOptimiser;
	gOptimiser.LearnRate = options.GLearnRate;
	dOptimiser = data.p2pModel.dOptimiser;
	dOptimiser.LearnRate = options.DLearnRate;
	
	iteration = gOptimiser.Iteration;
	startEpoch = floor(iteration/imageAndLabel.NumObservations*options.MiniBatchSize)+1;
end

%% Training loop
for epoch = startEpoch:options.MaxEpochs
	
	imageAndLabel = imageAndLabel.shuffle();
	
	while imageAndLabel.hasdata
		
		iteration = iteration + 1;
		
		data = imageAndLabel.read();
		if options.InputChannels>3
			thisInput = cat(5, data.A{:});
			thisTarget = cat(5, data.B{:});
			
			inputImage = dlarray(env(thisInput), 'SSSCB');
			targetImage = dlarray(env(thisTarget), 'SSSCB');
		else
			thisInput = cat(4, data.A{:});
			thisTarget = cat(4, data.B{:});
			
			inputImage = dlarray(env(thisInput), 'SSCB');
			targetImage = dlarray(env(thisTarget), 'SSCB');
		end
		
		[g, gLoss, d, dLoss, lossL1, ganLoss, ~] = ...
            dlfeval(@stepBoth_Deshan, g, d, gOptimiser, dOptimiser, inputImage, targetImage, options);
% 			asa(@stepBoth_Deshan, g, d, gOptimiser, dOptimiser, inputImage, targetImage, options);
			% dlfeval(@stepBoth, g, d, gOptimiser, dOptimiser, inputImage, targetImage, options);
        
		
		if mod(iteration, options.VerboseFrequency) == 0 || iteration == 2
			logArgs = {epoch, iteration,  ...
				gLoss, lossL1, ganLoss, dLoss};
			fprintf('epoch: %d, it: %d, G: %f (L1: %f, GAN: %f), D: %f\n', ...
				logArgs{:});
			if options.Plots == "training-progress"
				trainingPlot.update(logArgs{:}, g);
			end
		end
	end
	
	p2pModel = struct('g', g, 'd', d, 'gOptimiser', gOptimiser, 'dOptimiser', dOptimiser);
	if ~isempty(options.CheckpointPath)
        if mod(epoch, options.VerboseFrequency)
		    checkpointFilename = sprintf('p2p_checkpoint_%s_%04d.mat', datestr(now, 'YYYY-mm-DDTHH-MM-ss'), epoch);
		    p2pModel = gather(p2pModel);
		    save(fullfile(checkpointSubDir, checkpointFilename), 'p2pModel')
        end
	end
end
end

function [g, gLoss, d, dLoss, lossL1, ganLoss, images] = stepBoth(g, d, gOpt, dOpt, inputImage, targetImage, options)

% Make a fake image
fakeImage = tanh(g.forward(inputImage));

%% D update
% Apply the discriminator
if size(inputImage,3)>3
	realPredictions = sigmoid(d.forward(...
		cat(4, targetImage, inputImage) ...
		));
	fakePredictions = sigmoid(d.forward(...
		cat(4, fakeImage, inputImage)...
		));
else
	realPredictions = sigmoid(d.forward(...
		cat(3, targetImage, inputImage) ...
		));
	fakePredictions = sigmoid(d.forward(...
		cat(3, fakeImage, inputImage)...
		));
end

% calculate D losses
labels = ones(size(fakePredictions), 'single');
% crossentropy divides by nBatch, so we need to divide further
if size(inputImage,3)>3
	% 3D
	dLoss = options.DRelLearnRate*(crossentropy(realPredictions, labels)/numel(fakePredictions(:,:,:,1,1)) + ...
		crossentropy(1-fakePredictions, labels)/numel(fakePredictions(:,:,:,1,1)));
else
	dLoss = options.DRelLearnRate*(crossentropy(realPredictions, labels)/numel(fakePredictions(:,:,1,1)) + ...
		crossentropy(1-fakePredictions, labels)/numel(fakePredictions(:,:,1,1)));
end

% get d gradients
dGrads = dlgradient(dLoss, d.Learnables, "RetainData", true);
dLoss = extractdata(dLoss);

%% G update
% to save time I just use the existing result from d

% calculate g Losses
ganLoss = crossentropy(fakePredictions, labels)/numel(fakePredictions(:,:,1,1));
mask_band = (inputImage == min(inputImage(:)));
err_map = fakeImage - targetImage;
L1 = abs(err_map);
%     lossL1 = mean(L1, 'all');
L1a = L1(mask_band==1); % Inside the band
L1b = L1(mask_band==0); % Outside the band

% lossL1 = mean(L1(L1>1e-1), 'all') + mean(L1, 'all');
lossL1a = mean(L1a(L1a>1e-1), 'all') + mean(L1a, 'all');
lossL1b = mean(L1b(L1b>1e-1), 'all') + mean(L1b, 'all');
lossL1 = lossL1a + lossL1b;
if size(inputImage,3)>1
    weights = ones(3,3,3, 'single'); weights(2,2,2)=-26;
else
    weights = ones(3,3,1, 'single'); weights(2,2,1)=-8;
end
weights = dlarray(gpuArray(weights));
TV = abs(dlconv(err_map, weights, 0));
TVloss = mean(TV, 'all');
% lossL1 = lossL1 + TVloss*0.05;
lossL1 = lossL1 + TVloss*0.2;

%     lossL1 = mean((fakeImage - targetImage).^2, 'all');
gLoss = options.Lambda*lossL1 + ganLoss;

% get g grads
gGrads = dlgradient(gLoss, g.Learnables);

% update g
g.Learnables = dOpt.update(g.Learnables, gGrads);
% update d
d.Learnables = gOpt.update(d.Learnables, dGrads);
% things for plotting
gLoss = extractdata(gLoss);
lossL1 = extractdata(lossL1);
ganLoss = extractdata(ganLoss);

images = {fakeImage, inputImage, targetImage};
end

%%
function [g, gLoss, d, dLoss, lossL1, ganLoss, images] = stepBoth_Deshan(g, d, gOpt, dOpt, inputImage, targetImage, options)
mask_band = (inputImage == min(inputImage(:)));

% Make a fake image
fakeImage = tanh(g.forward(inputImage));
fakeImage(mask_band==0) = inputImage(mask_band==0);

%% D update
% Apply the discriminator
if size(inputImage,3)>3
	realPredictions = sigmoid(d.forward(...
		cat(4, targetImage, inputImage) ...
		));
	fakePredictions = sigmoid(d.forward(...
		cat(4, fakeImage, inputImage)...
		));
else
	realPredictions = sigmoid(d.forward(...
		cat(3, targetImage, inputImage) ...
		));
	fakePredictions = sigmoid(d.forward(...
		cat(3, fakeImage, inputImage)...
		));
end

% calculate D losses
labels = ones(size(fakePredictions), 'single');
% crossentropy divides by nBatch, so we need to divide further
if size(inputImage,3)>3
	% 3D
	dLoss = options.DRelLearnRate*(crossentropy(realPredictions, labels)/numel(fakePredictions(:,:,:,1,1)) + ...
		crossentropy(1-fakePredictions, labels)/numel(fakePredictions(:,:,:,1,1)));
else
	dLoss = options.DRelLearnRate*(crossentropy(realPredictions, labels)/numel(fakePredictions(:,:,1,1)) + ...
		crossentropy(1-fakePredictions, labels)/numel(fakePredictions(:,:,1,1)));
end

% get d gradients
dGrads = dlgradient(dLoss, d.Learnables, "RetainData", true);
dLoss = extractdata(dLoss);

%% G update
% to save time I just use the existing result from d

% calculate g Losses
ganLoss = crossentropy(fakePredictions, labels)/numel(fakePredictions(:,:,1,1));
err_map = fakeImage - targetImage;
L1 = abs(err_map.^2);
%     lossL1 = mean(L1, 'all');
L1a = L1(mask_band==1); % Inside the band
lossL1 = mean(L1a(L1a>1e-1), 'all') + mean(L1a, 'all');

weights = ones(3,3,3, 'single'); weights(2,2,2)=-26;
weights = dlarray(gpuArray(weights));
TV = abs(dlconv(err_map, weights, 0));
mask_band_2 = mask_band(2:end-1, 2:end-1, 2:end-1, :, :);
TV = TV(mask_band_2==1);  % Only in the band
TVloss = mean(TV(TV>1e-2), 'all') + mean(TV, 'all');
lossL1 = lossL1 + TVloss*0.5;

gLoss = options.Lambda*lossL1 + ganLoss;

% get g grads
gGrads = dlgradient(gLoss, g.Learnables);

% update g
g.Learnables = dOpt.update(g.Learnables, gGrads);
% update d
d.Learnables = gOpt.update(d.Learnables, dGrads);
% things for plotting
gLoss = extractdata(gLoss);
lossL1 = extractdata(lossL1);
ganLoss = extractdata(ganLoss);

images = {fakeImage, inputImage, targetImage};
end

