function p2pModel = p2ptrain_cardiac(MaskedImgDir, GTImgDir, PointsDir,ValMaskedImgDir, ValGTImgDir, ValPointsDir, options)
% train     Train a pix2pix model.
%
%   A pix2pix model that attempts to learn how to convert images from
%   inData to outData is trained, following the approach described in
%   'Isola et al. Image-to-Image Translation with Conditional Adversarial
%   Nets'.
%
% Args:
%   inData  - Training data input images
%   outData - Training data target images
%   options - Training options as a struct generated by p2p.trainingOptions
%
% Returns:
%   p2pModel - A struct containing trained newtorks and optimisiers
%
% See also: p2p.trainingOptions

% Copyright 2020 The MathWorks, Inc.

if nargin < 3
	options = p2p.getDefaultOptions();
end

if (options.ExecutionEnvironment == "auto" && canUseGPU) || ...
		options.ExecutionEnvironment == "gpu"
	env = @gpuArray;
else
	env = @(x) x;
end

if ~isempty(options.CheckpointPath)
	% Make a subfolder for storing checkpoints
	timestamp = strcat("p2p-", datestr(now, 'yyyymmdd-HHMMSS'));
	checkpointSubDir = fullfile(options.CheckpointPath, timestamp);
	mkdir(checkpointSubDir)
end

if isempty(options.ResumeFrom)
    % 3D
    g0 = createUnet3dLayers_cardiac([options.InputSize options.InputChannels], 1, 'EncoderDepth', options.GDepth, 'BatchNormalizationFirstLayer', false, 'InputNormalization', false, ...
        'NumEncoderFilters', [16 32 48 64 96 128], 'NumDecoderFilters', [128 96 64 48 32 16], 'Z_Half_SampleRates', [2 2 2 1 1 1], 'DownSamplePooling', 'max');
    %             g0 = createUnet3dLayers_Deshan(options.InputSize, 1, 'EncoderDepth', options.GDepth, 'BatchNormalizationFirstLayer', false, 'InputNormalization', false, ...
    %                 'NumEncoderFilters', [16 32 48 64 96 128], 'NumDecoderFilters', [128 96 64 64 64 32], 'Z_Half_SampleRates', [2 2 1 1 1], 'DownSamplePooling', 'average');
    g0 = removeLayers(g0, {'Segmentation-Layer', 'Softmax-Layer'});
    g = dlnetwork(g0);
    d = p2p.networks.discriminator3d(options.InputSize, 2, options.DDepth);
	
	gOptimiser = p2p.util.AdamOptimiser(options.GLearnRate, options.GBeta1, options.GBeta2);
	dOptimiser = p2p.util.AdamOptimiser(options.DLearnRate, options.DBeta1, options.DBeta2);
	
	iteration = 0;
	startEpoch = 1;
else
    if "last"==options.ResumeFrom
        files = dir(fullfile(options.CheckpointPath, '*', 'p2p_checkpoint*.mat'));
        [~, idx] = max([files.datenum]);
        options.ResumeFrom = fullfile(files(idx).folder, files(idx).name);
    end

	data = load(options.ResumeFrom, 'p2pModel');
	g = data.p2pModel.g;
	d = data.p2pModel.d;
	gOptimiser = data.p2pModel.gOptimiser;
	gOptimiser.LearnRate = options.GLearnRate;
	dOptimiser = data.p2pModel.dOptimiser;
	dOptimiser.LearnRate = options.DLearnRate;
	
	iteration = gOptimiser.Iteration;
	startEpoch = floor(iteration/imageAndLabel.NumObservations*options.MiniBatchSize/100)+1;
end


% model learns A to B mapping
ValidationimageAndLabel = p2p.data.PairedImageDatastore_Cardiac(ValMaskedImgDir, ValGTImgDir, ValPointsDir, options.MiniBatchSize, ...
	"PreSize", options.PreSize, "CropSize", options.InputSize, ...
	"ARange", options.ARange, "BRange", options.BRange);

if options.Plots == "training-progress"
	examples = ValidationimageAndLabel.shuffle();
	nExamples = 90;
	examples.MiniBatchSize = nExamples;
	data = examples.read();
	%         thisInput = min(max(thisInput, -0.2),0.2);
    thisInput = cat(5, data.A{:});
    exampleInputs = dlarray(env(thisInput), 'SSSCB');
	trainingPlot = p2p.vis.TrainingPlot(exampleInputs);
end

imageAndLabel = p2p.data.PairedImageDatastore_Cardiac(MaskedImgDir, GTImgDir, PointsDir, options.MiniBatchSize, ...
	"PreSize", options.PreSize, "CropSize", options.InputSize, ...
	"ARange", options.ARange, "BRange", options.BRange);

%% Training loop
for epoch = startEpoch:options.MaxEpochs
	
	imageAndLabel = imageAndLabel.shuffle();
	% imageAndLabel.data_current_index = randi(length(imageAndLabel.data_indices));
	while imageAndLabel.hasdata
		
		iteration = iteration + 1;
		
		data = imageAndLabel.read();
        thisInput = cat(5, data.A{:});
        thisTarget = cat(5, data.B{:});

        inputImage = dlarray(env(thisInput), 'SSSCB');
        targetImage = dlarray(env(thisTarget), 'SSSCB');
		
		[g, gLoss, d, dLoss, lossL1, ganLoss, ~] = ...
            dlfeval(@stepBoth, g, d, gOptimiser, dOptimiser, inputImage, targetImage, options);
		
		if mod(iteration, options.VerboseFrequency) == 0 || iteration == 2
			ValidationimageAndLabel = ValidationimageAndLabel.shuffle();
            Validationdata=imageAndLabel.read();
            validationInput = cat(5,Validationdata.A{:});
            validationTarget=cat(5,Validationdata.B{:});
            validationImage=dlarray(env(validationInput),'SSSCB');
            validationTargetImage=dlarray(env(validationTarget),'SSSCB');
            [ValidationL1Loss]=dlfeval(@Validation_Results,g,validationImage,validationTargetImage);
            logArgs = {epoch, iteration,  ...
				gLoss, lossL1, ganLoss, dLoss,ValidationL1Loss};
			fprintf('epoch: %d, it: %d, G: %f (L1: %f, GAN: %f), D: %f, ValidationL1: %f\n', ...
				logArgs{:});
			if options.Plots == "training-progress"
				trainingPlot.update(logArgs{1:6}, g);
			end
		end
	end
	
	p2pModel = struct('g', g, 'd', d, 'gOptimiser', gOptimiser, 'dOptimiser', dOptimiser);
	if ~isempty(options.CheckpointPath)
        if mod(epoch, options.VerboseFrequency)
		    checkpointFilename = sprintf('p2p_checkpoint_%s_%04d.mat', datestr(now, 'YYYY-mm-DDTHH-MM-ss'), epoch);
		    p2pModel = gather(p2pModel);
		    save(fullfile(checkpointSubDir, checkpointFilename), 'p2pModel')
        end
	end
end
end

function [g, gLoss, d, dLoss, lossL1, ganLoss, images] = stepBoth(g, d, gOpt, dOpt, inputImage, targetImage, options)
%%
inputImage2 = inputImage(:,:,:,1,:);
inputImageMask = inputImage(:,:,:,2,:);
mask_band = inputImageMask>0;
inputImage(mask_band==1)=0;

% Make a fake image
fakeImage = tanh(g.forward(inputImage));
fakeImage(mask_band==0) = inputImage2(mask_band==0);

%% D update
% Apply the discriminator
realPredictions = sigmoid(d.forward(...
    cat(4, targetImage, inputImage2) ...
    ));
fakePredictions = sigmoid(d.forward(...
    cat(4, fakeImage, inputImage2)...
    ));

% calculate D losses
labels = ones(size(fakePredictions), 'single');
% crossentropy divides by nBatch, so we need to divide further
% 3D
dLoss = options.DRelLearnRate*(crossentropy(realPredictions, labels)/numel(fakePredictions(:,:,:,1,1)) + ...
    crossentropy(1-fakePredictions, labels)/numel(fakePredictions(:,:,:,1,1)));

% get d gradients
dGrads = dlgradient(dLoss, d.Learnables, "RetainData", true);
dLoss = extractdata(dLoss);

%% G update
% to save time I just use the existing result from d

% calculate g Losses
ganLoss = crossentropy(fakePredictions, labels)/numel(fakePredictions(:,:,1,1));
err_map = fakeImage - targetImage;
L1 = abs(err_map.^2);
%     lossL1 = mean(L1, 'all');
L1a = L1(mask_band==1); % Inside the band
if any(L1a(:)>1e-1)
    lossL1 = mean(L1a(L1a>1e-1), 'all') + mean(L1a, 'all');
else
    lossL1 = 2*mean(L1a,'all');
end


% lossL1 = mean(L1a,'all')+mean(L1,'all');
weights = ones(3,3,3, 'single'); weights(2,2,2)=-26;
weights = dlarray(gpuArray(weights));
TV = abs(dlconv(err_map, weights, 0));
mask_band_2 = mask_band(2:end-1, 2:end-1, 2:end-1, :, :);
% mask_band_2=extractdata(mask_band);
% mask_band_2=imdilate(mask_band_2,strel('disk',2));
% mask_band_2=dlarray(mask_band_2);
TV = TV(mask_band_2==1);  % Only in the band
if any(TV(:)>1e-2)
    TVloss = mean(TV(TV>1e-2), 'all') + mean(TV, 'all');
else
    TVloss = 2*mean(TV,'all');
end
% TVloss = TVloss*100;

lossL1 = lossL1 + TVloss*.01;
lossL1 = lossL1*100;

gLoss = options.Lambda*lossL1 + ganLoss;

% get g grads
gGrads = dlgradient(gLoss, g.Learnables);

% update g
g.Learnables = dOpt.update(g.Learnables, gGrads);
% update d
d.Learnables = gOpt.update(d.Learnables, dGrads);
% things for plotting
gLoss = extractdata(gLoss);
lossL1 = extractdata(lossL1);
ganLoss = extractdata(ganLoss);

images = {fakeImage, inputImage2, targetImage};
end

function [validationlossL1] = Validation_Results(g, inputImage, targetImage)
inputImage2 = inputImage(:,:,:,1,:);
inputImageMask = inputImage(:,:,:,2,:);
mask_band = inputImageMask>0;
inputImage(mask_band==1)=0;

% Make a fake image
fakeImage = tanh(g.forward(inputImage));
fakeImage(mask_band==0) = inputImage2(mask_band==0);

err_map = fakeImage - targetImage;
L1 = abs(err_map.^2);
%     lossL1 = mean(L1, 'all');
L1a = L1(mask_band==1); % Inside the band
if any(L1a(:)>1e-1)
    lossL1 = mean(L1a(L1a>1e-1), 'all') + mean(L1a, 'all');
else
    lossL1 = 2*mean(L1a,'all');
end

weights = ones(3,3,3, 'single'); weights(2,2,2)=-26;
weights = dlarray(gpuArray(weights));
TV = abs(dlconv(err_map, weights, 0));
mask_band_2 = mask_band(2:end-1, 2:end-1, 2:end-1, :, :);
TV = TV(mask_band_2==1);  % Only in the band
if any(TV(:)>1e-2)
    TVloss = mean(TV(TV>1e-2), 'all') + mean(TV, 'all');
else
    TVloss = 2*mean(TV,'all');
end
validationlossL1 = lossL1 + TVloss*.01;
validationlossL1 = validationlossL1*100;

validationlossL1 = extractdata(validationlossL1);
end